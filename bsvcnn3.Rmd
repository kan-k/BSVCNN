---
title: "bsvcnn3"
output: html_document
---

Use a new (smaller) mask `/well/nichols/users/kfh142/data/Atlas/CIC/MultRes` namely `CICatlas_Res3_2mm.nii.gz`

```{r}
temp.img <-oro.nifti::readNIfTI('/well/nichols/users/kfh142/data/Atlas/CIC/MultRes/CICatlas_Res3_2mm.nii.gz')
length(unique(c(temp.img))) #number of region
```
Take `Res3` where `HO-combined-fin.nii.gz` is non-zero

```{r}
mask.com<-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bsvcnn/pile/HO-combined-fin.nii.gz')

temp.img[mask.com==0] <- 0
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,paste0('/well/nichols/users/qcv214/bnn2/res3/res3mask'))
```
Then only keep GM using `CICatlas_Res3_trunc.txt`.


In fact let's not threshold by `HO-combined-fin.nii.gz`

`CICatlas_Res3_trunc.txt ` says everything above label 12 is not GM, then threshold at 0.1, so 
```{r}
temp.img <-oro.nifti::readNIfTI('/well/nichols/users/kfh142/data/Atlas/CIC/MultRes/CICatlas_Res3_2mm.nii.gz')
#Take only grey matter
temp.img[temp.img>12] <- 0
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,paste0('/well/nichols/users/qcv214/bnn2/res3/res3mask'))
#Load data with new unthreshold mask
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
part_use<-part_list[part_list$exist_vbm==1,] #4263 participants left
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_use[1:(dim(part_use)[1]),1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
res3.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask') 
#threshold at 0.1
dat_colmeans<-colMeans(res3.dat)
temp.img[temp.img>1][dat_colmeans<0.1] <- 0 
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/res3mask')
#Load data again using the new thresholded mask
res3.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask') # 4263 x 163375
#save datat
write_feather(as.data.frame(res3.dat), '/well/nichols/users/qcv214/bnn2/res3/res3_dat.feather')
#reload data and mask
res3.dat <- read_feather('/well/nichols/users/qcv214/bnn2/res3/res3_dat.feather') #dim = 4263 124859
res3.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
res3.mask.reg <- setdiff(sort(unique(c(res3.mask))),0)
```

##Create mask ROI
Don't RUN
```{r}
#Don't RUN
res3.mask.reg <- sort(unique(c(res3.mask)))
for(i in res3.mask.reg){
  temp.img <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
  temp.img <- temp.img == i 
  temp.img@datatype = 2
  temp.img@bitpix = 8
  writeNIfTI(temp.img,paste0('/well/nichols/users/qcv214/bnn2/res3/roi/mask_ROI_',i))
  temp.dat <- fast_read_imgs_mask(list_of_all_images,paste0('/well/nichols/users/qcv214/bnn2/res3/roi/mask_ROI_',i)) # 4263 x 163375
  write_feather(as.data.frame(temp.dat), paste0('/well/nichols/users/qcv214/bnn2/res3/roi/dat_ROI_',i))
}
```

Create `rearranged data`
```{r}
#dat.temp <- matrix(nrow = nrow(res3.dat),ncol = sum(res3.mask>0))
dat.temp <- matrix(nrow = nrow(res3.dat),ncol = 1)
  cum.length <- 0
for(i in res3.mask.reg){
  roi.reg<- read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/roi/dat_ROI_",i,'.feather'))
  print(dim(roi.reg))
  cum.length <- cum.length + ncol(roi.reg)
  print(cum.length)
  roi.reg<- as.matrix(roi.reg)
  dat.temp <- cbind(dat.temp, roi.reg)
}
colnames(dat.temp) <- NULL
dat.temp <- as.data.frame(dat.temp[,-1])
dat.temp <- as.matrix(dat.temp)
write_feather(as.data.frame(dat.temp), '/well/nichols/users/qcv214/bnn2/res3/dat_rearranged.feather')
```

Try loading partial gp from `partial_gp.R`
```{r}
  poly_degree = 10
  a_concentration = 0.5
  b_smoothness = 40
test.partial.gp <- read_feather("/well/nichols/users/qcv214/bnn2/res3/roi/partial_gp_1_fixed_100.540.feather")
```


#7 Mar
Save age to a file
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
part_use<-part_list[part_list$exist_vbm==1,] #4263 participants left
# 
agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
write_feather(age_tab, '/well/nichols/users/qcv214/bnn2/res3/age.feather')
```

#8 Mar
Load data from `nn_lr.R`
```{r}
num.batch <- 4
epoch <- 10

lr_vec <- c(1,10^-(5:11)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,8,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_loss_",i,".csv")))
}
```
Plot training rmse
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))))
# lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 2)
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3)
# lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 4)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 5)
# lines(sqrt(res.nn.loss[1,6,]),type=line.type,col = 6)
lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 7)
# lines(sqrt(res.nn.loss[1,8,]),type=line.type,col = 8)

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))))
# lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 2)
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3)
# lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 4)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 5)
# lines(sqrt(res.nn.loss[2,6,]),type=line.type,col = 6)
lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 7)
# lines(sqrt(res.nn.loss[2,8,]),type=line.type,col = 8)
```



plot some
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:10,lwd=0.2)

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:10,lwd=0.2)

legend('bottomright',legend = c('learning_rate','1e-4','1e-6','1e-8','1e-10'), pch = 1,col=c("white",1,3,10,12))
```
14 Mar

Get the weights
```{r}
num.batch <- 4
epoch <- 10

#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_weights_",10^-10,".feather")))
```

```{r}
plot(density(w.1e10[1,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,])
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```




#21 Mar
Load data from `nn_lr3.R`
```{r}
num.batch <- 4
epoch <- 30

failed_run <- c(5,7,9,10)
lr_vec <- c(10^- setdiff((1:11),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,11,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn3_loss_",i,".csv")))
}

res.nn.loss <- res.nn.loss[, 1:length(lr_vec),]

```
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:10,lwd=0.2)

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:10,lwd=0.2)

legend('bottomright',legend = c('learning_rate','1e-01','1e-3','1e-6','1e-8'), pch = 1,col=c("white",1,3,10,12))
```
Get the weights
```{r}
num.batch <- 4
epoch <- 30
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn3_weights_",10^-1,".feather")))
```

```{r}
plot(density(w.1e10[1,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,])
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```


#22 Mar
Load data from `nn_lr4.R`
```{r}
num.batch <- 4
epoch <- 30

failed_run <- c(4,5,9)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn4_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),]
```
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate','0.1','0.3','0.7'), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate','0.1','0.3','0.7'), pch = 1,col=c("white",1,3,10))
```
Get theta
```{r}
num.batch <- 4
epoch <- 30
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn4_theta_",0.3,".feather")))
plot(density(w.1e10[1,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```


Load data from `nn_lr5.R`

40 iterations in 2hrs and 20 mins
```{r}
num.batch <- 4
epoch <- 40

failed_run <- c(5,9)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn5_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),]
```
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate','0.2','0.4','0.7'), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate','0.1','0.3','0.6'), pch = 1,col=c("white",1,3,10))
```
Get theta
```{r}
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn5_theta_",0.6,".feather")))
plot(density(w.1e10[1,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```



#23 Mar
##Newton method
Load data from `nn_lr_nm1.R`
```{r}
num.batch <- 4
epoch <- 30
failed_run<-c()
res.nn.loss <- array(, dim = c(2,3,num.batch*epoch )) 
for( i in setdiff(2:4,failed_run)){  
  res.nn.loss[,which(i==2:4),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_nm1_loss_jobid_",i,".csv")))
}

```
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 4,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('run','1','2'), pch = 1,col=c("white",1,3))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 4,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('run','1','2'), pch = 1,col=c("white",1,3))

plot(sqrt(res.nn.loss[2,1,]),type=line.type,lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 4,lwd=2)
legend('bottomleft',legend = c('run','1','2'), pch = 1,col=c("white",1,3))


plot(sqrt(res.nn.loss[2,3,]),type=line.type,lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,1,]),type=line.type,col = 4,lwd=2)
legend('bottomleft',legend = c('run','1','2'), pch = 1,col=c("white",1,3))

```
It's not working.. and green line is kinda unpredictable 










#24 Mar
Load whole brain for benchmark from `whole_brain.R`
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
```{r}
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
wb_23mar<-array(,dim=c(50,3,14))
failed_run<-c()
for(i in setdiff(1:50,failed_run)){
      wb_23mar[i,,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/whole_brain",poly_degree,a_concentration,b_smoothness,"_",i,".csv")))
}
#bsvcnn.11feb.def<-bsvcnn.11feb.def[-failed_run,,]
wb_23mar.m<-apply(wb_23mar, c(2,3), median)
plot.box(wb_23mar)
wb_23mar.m[1,3]
```

```{r}
plot.box(wb_23mar)
```


#25 Mar and 27 mar
I think batch size too small 
##Adam
Load data from `nn_adam.R`
```{r}
num.batch <- 20
epoch <- 50

failed_run <- c()
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){
  # print(i)
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam1_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```

```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('topleft',legend = c('learning_rate',as.character(lr_vec[c(1,3,5,7)])), pch = 1,col=c("white",1,3,10,12))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,3,5,7)])), pch = 1,col=c("white",1,3,10,12))
```
Get theta
```{r}
num.batch <- 4
epoch <- 20
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam1_theta_",0.1,".feather")))
plot(density(w.1e10[4,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```

##Adam with de-coupled weights
Load data from `nn_adamW.R`

```{r}
num.batch <- 20
epoch <- 50

failed_run <- c(4,5)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW1_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),]
```

```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate','0.1','0.2','0.3'), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate','0.1','0.2','0.3'), pch = 1,col=c("white",1,3,10))
```
Get theta
```{r}
num.batch <- 4
epoch <- 10
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW1_theta_",0.1,".feather")))
plot(density(w.1e10[1,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```


#28 Mar
##Adam
Load data from `nn_adam.R`
```{r}
num.batch <- 4
epoch <- 20

failed_run <- c(4,5,6,7)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){
   print(i)
  print(which(i==lr_vec))
  if(i == 1){res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",i,".csv")))}
  else{res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam2_loss_",i,".csv")))[,1:80]}
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```
```{r}
num.batch <- 4
epoch <- 20

failed_run <- c(4,5,6,7)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
res.nn.loss[,1,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",0.1,".csv")))
for( i in lr_vec){
   print(i)
  print(which(i==lr_vec))
res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam2_loss_",i,".csv")))[,1:80]
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```

```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,3,5)])), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,3,5)])), pch = 1,col=c("white",1,3,10))

plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")

res.nn.loss2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",0.1,".csv")))
plot(sqrt(res.nn.loss2[2,]),type=line.type, ylim = c(min(sqrt(res.nn.loss2[2,])), max(sqrt(res.nn.loss2[2,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
```
Get theta
```{r}
num.batch <- 4
epoch <- 20
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_theta_",0.1,".feather")))
plot(density(w.1e10[7,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```


##AdamW
Load data from `nn_adamW.R`
```{r}
num.batch <- 4
epoch <- 30

failed_run <- c(3,5,7,8,9)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){
   print(i)
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW2_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,3,5)])), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2,4)])), pch = 1,col=c("white",1,3,10))
```
Get theta
```{r}
num.batch <- 4
epoch <- 30
#Get the best performance
w.1e10 <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW2_theta_",0.1,".feather")))
plot(density(w.1e10[4,]))
# lines(density(w.1e10[2,]))
# lines(density(w.1e10[3,]))
for(i in 1:12){
  qqnorm(w.1e10[i,], main = paste0("Normal Q-Q Plot of Region #",i))
  #abline(a=0,b=1, col = 'red')
  qqline(w.1e10[i,])
}
```


##Summmary so far
In the setting of 2,000 training, 2,000 testing with 500 batch size and 20 epochs
1.SGD with lr = 0.6 (originally had 40 epochs) `nn_lr5.R`
2.newton method jobid 2
3. Adam with lr = 0.1, too many hyperparameters to set 
4. Adam with weight decay with lr = 0.3
5. Adam with small batch (not working so well), lr = 0.1
6. [Benchmark] whole brain 
###Load all data 
```{r}
#SGD
res.nn.loss.sgd <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn5_loss_",0.6,".csv")))
#Newton
res.nn.loss.nm <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_nm1_loss_jobid_",4,".csv")))
#Adam
res.nn.loss.adam <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",0.1,".csv")))
#Adam with decoupled weight decay
res.nn.loss.adamw <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW2_loss_",0.3,".csv")))
#Adam with small batch
res.nn.loss.adam_s <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam1_loss_",0.1,".csv")))
```
###Load whole brain
```{r}
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
wb_23mar<-array(,dim=c(50,3,14))
failed_run<-c()
for(i in setdiff(1:50,failed_run)){
      wb_23mar[i,,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/whole_brain",poly_degree,a_concentration,b_smoothness,"_",i,".csv")))
}
wb_23mar.m<-apply(wb_23mar, c(2,3), median)
```

###Concat the results
```{r}
min.it <- min(ncol(res.nn.loss.sgd),ncol(res.nn.loss.nm),ncol(res.nn.loss.adam),ncol(res.nn.loss.adamw),ncol(res.nn.loss.adam_s))
full.res.out <- rbind(sqrt(res.nn.loss.sgd[2,1:min.it]),sqrt(res.nn.loss.nm[2,1:min.it]), sqrt(res.nn.loss.adam[2,1:min.it]), sqrt(res.nn.loss.adamw[2,1:min.it]), sqrt(res.nn.loss.adam_s[2,1:min.it]),wb_23mar.m[1,6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd[1,1:min.it]),sqrt(res.nn.loss.nm[1,1:min.it]), sqrt(res.nn.loss.adam[1,1:min.it]), sqrt(res.nn.loss.adamw[1,1:min.it]), sqrt(res.nn.loss.adam_s[1,1:min.it]),wb_23mar.m[1,5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```

```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,],type=line.type,col = 3,lwd=2)
lines(full.res[1,4,],type=line.type,col = 4,lwd=2)
lines(full.res[1,5,],type=line.type,col = 5,lwd=2)
lines(full.res[1,6,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Newton","Adam", "AdamW", "Adam_s","Whole"), pch = 1,col=c("white",1:6))

#out-of-sample
plot(full.res[2,1,],type=line.type, ylim = c(min(full.res[2,,]), 
                                             7#max(full.res[2,,])
                                             ),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,],type=line.type,col = 3,lwd=2)
lines(full.res[2,4,],type=line.type,col = 4,lwd=2)
lines(full.res[2,5,],type=line.type,col = 5,lwd=2)
lines(full.res[2,6,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Newton","Adam", "AdamW", "Adam_s","Whole"), pch = 1,col=c("white",1:6))
```


Deleting Newton and Adam_s

```{r}
min.it <- min(ncol(res.nn.loss.sgd),ncol(res.nn.loss.adam),ncol(res.nn.loss.adamw),ncol(res.nn.loss.adam_s))
full.res.out <- rbind(sqrt(res.nn.loss.sgd[2,1:min.it]), sqrt(res.nn.loss.adam[2,1:min.it]), sqrt(res.nn.loss.adamw[2,1:min.it]),wb_23mar.m[1,6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd[1,1:min.it]), sqrt(res.nn.loss.adam[1,1:min.it]), sqrt(res.nn.loss.adamw[1,1:min.it]),wb_23mar.m[1,5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```

```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,-c(2,5),]), max(full.res[1,-c(2,5),])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,5,],type=line.type,col = 5,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Adam", "AdamW","WB_Reg"),lty=c(1,1,2,3,1), pch = c(1,1,2,3,20),col=c("white",1,3,4,6))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,-c(2,5),]), max(full.res[2,-c(2,5),])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,5,],type=line.type,col = 5,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Adam", "AdamW","WB_Reg"),lty=c(1,1,2,3,1), pch = c(1,1,2,3,20),col=c("white",1,3,4,6))
```

Tom's meeting 28 March

1. deffo fix bias for each regression
2. Look into the scattered mask
3.Investigate loading time
Maybe
4. Try to mimic the neural nets to look similar to whole brain GP

Investigating mask
`CICatlas_Res3_trunc.txt ` says everything above label 12 is not GM, then threshold at 0.1, so 
```{r}
temp.img <-oro.nifti::readNIfTI('/well/nichols/users/kfh142/data/Atlas/CIC/MultRes/CICatlas_Res3_2mm.nii.gz')
#Take only grey matter
temp.img[temp.img>12] <- 0
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,paste0('/well/nichols/users/qcv214/bnn2/res3/maskfix/res3mask_1'))
#Load data with new unthreshold mask
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
part_use<-part_list[part_list$exist_vbm==1,] #4263 participants left
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_use[1:(dim(part_use)[1]),1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
res3.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/maskfix/res3mask_1') 
#threshold at 0.1
dat_colmeans<-colMeans(res3.dat)
#Originally I had temp.img > 1, that means it's not thresholded by 
# temp.img[temp.img>1][dat_colmeans<0.1] <- 0 
# temp.img@datatype = 2
# temp.img@bitpix = 8
# writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/maskfix/res3mask_2')

#
temp.img[temp.img>0][dat_colmeans<0.1] <- 0 
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/maskfix/res3mask_3') #Correct
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/res3mask')

#Load data again using the new thresholded mask
res3.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask') # 4263 x 156812
#save datat
write_feather(as.data.frame(res3.dat), '/well/nichols/users/qcv214/bnn2/res3/res3_dat.feather')
#reload data and mask
res3.dat <- read_feather('/well/nichols/users/qcv214/bnn2/res3/res3_dat.feather') #dim = 4263 156812
res3.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
res3.mask.reg <- setdiff(sort(unique(c(res3.mask))),0)
```

Create mean mask
```{r}
dat_colmeans<-colMeans(res3.dat)

temp.img <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
temp.img[temp.img>0] <- dat_colmeans 
temp.img@datatype = 16
temp.img@bitpix = 32
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/mean_mask') #Correct
```


Create `rearranged data`
```{r}
#dat.temp <- matrix(nrow = nrow(res3.dat),ncol = sum(res3.mask>0))
dat.temp <- matrix(nrow = nrow(res3.dat),ncol = 1)
  cum.length <- 0
for(i in res3.mask.reg){
  roi.reg<- read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/roi/dat_ROI_",i,'.feather'))
  print(dim(roi.reg))
  cum.length <- cum.length + ncol(roi.reg)
  print(cum.length)
  roi.reg<- as.matrix(roi.reg)
  dat.temp <- cbind(dat.temp, roi.reg)
}
colnames(dat.temp) <- NULL
dat.temp <- as.data.frame(dat.temp[,-1])
dat.temp <- as.matrix(dat.temp)
write_feather(as.data.frame(dat.temp), '/well/nichols/users/qcv214/bnn2/res3/dat_rearranged.feather')
```


Load data from `nn_lr6.R`
```{r}
num.batch <- 4
epoch <-30

failed_run <- c(3,5,7,8,9)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){  
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn6_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),]
```
```{r}
line.type <- 'b'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,3,4)])), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 10,lwd=2)
#lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,3,4)])), pch = 1,col=c("white",1,3,10))
```

##Summmary so far
In the setting of 2,000 training, 2,000 testing with 500 batch size and 20 epochs
1.SGD with lr = 0.6 (originally had 40 epochs) `nn_lr5.R`
2.newton method jobid 2
3. Adam with lr = 0.1, too many hyperparameters to set 
4. Adam with weight decay with lr = 0.3
5. Adam with small batch (not working so well), lr = 0.1
6. [Benchmark] whole brain 
###Load all data 
```{r}
#SGD
res.nn.loss.sgd <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn6_loss_",0.6,".csv")))
#Newton
res.nn.loss.nm <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_nm1_loss_jobid_",4,".csv")))
#Adam
res.nn.loss.adam <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",0.1,".csv")))
#Adam with decoupled weight decay
res.nn.loss.adamw <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adamW2_loss_",0.1,".csv")))
#Adam with small batch
res.nn.loss.adam_s <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam1_loss_",0.1,".csv")))
```
###Load whole brain
```{r}
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
wb_23mar<-array(,dim=c(50,3,14))
failed_run<-c()
for(i in setdiff(1:50,failed_run)){
      wb_23mar[i,,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/whole_brain",poly_degree,a_concentration,b_smoothness,"_",i,".csv")))
}
wb_23mar.m<-apply(wb_23mar, c(2,3), median)
```

###Concat the results
```{r}
min.it <- min(ncol(res.nn.loss.sgd),ncol(res.nn.loss.nm),ncol(res.nn.loss.adam),ncol(res.nn.loss.adamw),ncol(res.nn.loss.adam_s))
full.res.out <- rbind(sqrt(res.nn.loss.sgd[2,1:min.it]),sqrt(res.nn.loss.nm[2,1:min.it]), sqrt(res.nn.loss.adam[2,1:min.it]), sqrt(res.nn.loss.adamw[2,1:min.it]), sqrt(res.nn.loss.adam_s[2,1:min.it]),wb_23mar.m[1,6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd[1,1:min.it]),sqrt(res.nn.loss.nm[1,1:min.it]), sqrt(res.nn.loss.adam[1,1:min.it]), sqrt(res.nn.loss.adamw[1,1:min.it]), sqrt(res.nn.loss.adam_s[1,1:min.it]),wb_23mar.m[1,5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```

```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,],type=line.type,col = 3,lwd=2)
lines(full.res[1,4,],type=line.type,col = 4,lwd=2)
lines(full.res[1,5,],type=line.type,col = 5,lwd=2)
lines(full.res[1,6,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Newton","Adam", "AdamW", "Adam_s","Whole"), pch = 1,col=c("white",1:6))

#out-of-sample
plot(full.res[2,1,],type=line.type, ylim = c(min(full.res[2,,]), min(max(full.res[2,,]),7)),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,],type=line.type,col = 3,lwd=2)
lines(full.res[2,4,],type=line.type,col = 4,lwd=2)
lines(full.res[2,5,],type=line.type,col = 5,lwd=2)
lines(full.res[2,6,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomright',legend = c('method',"SGD","Newton","Adam", "AdamW", "Adam_s","Whole"), pch = 1,col=c("white",1:6))
```

Deleting Newton and Adam_s

```{r}
min.it <- min(ncol(res.nn.loss.sgd),ncol(res.nn.loss.adam),ncol(res.nn.loss.adamw),ncol(res.nn.loss.adam_s))
full.res.out <- rbind(sqrt(res.nn.loss.sgd[2,1:min.it]), sqrt(res.nn.loss.adam[2,1:min.it]), sqrt(res.nn.loss.adamw[2,1:min.it]),wb_23mar.m[1,6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd[1,1:min.it]), sqrt(res.nn.loss.adam[1,1:min.it]), sqrt(res.nn.loss.adamw[1,1:min.it]),wb_23mar.m[1,5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```

```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,5,],type=line.type,col = 5,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('method',"SGD","Adam", "AdamW","WB_Reg"),lty=c(1,1,2,3,1), pch = c(1,1,2,3,20),col=c("white",1,3,4,6))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,5,],type=line.type,col = 5,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('method',"SGD","Adam", "AdamW","WB_Reg"),lty=c(1,1,2,3,1), pch = c(1,1,2,3,20),col=c("white",1,3,4,6))
```

```{r}
plot(sqrt(res.nn.loss.adam[2,1:min.it]))
```




#After adding bias
##Adam
Load data from `nn_adam_b1.R`
```{r}
num.batch <- 4
epoch <- 20

failed_run <- c(1,3,6,8)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adam1_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,3,5)])), pch = 1,col=c("white",1,3,10))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,3,5)])), pch = 1,col=c("white",1,3,10))
```

Get bias
```{r}
num.batch <- 4
epoch <- 20
#Get the best performance
w.1e10 <- as.matrix(read.csv('/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adam1_theta_0.2.csv'))
plot(w.1e10)
```

##SGD
Load data from `nnb1.R`
Not working great
```{r}
num.batch <- 4
epoch <- 20

failed_run <- c(1:6,9)
lr_vec <- c(10^(-1)*setdiff((1:9),failed_run)) #Note that 1 is not lr = 1, but lr = 1e-4
res.nn.loss <- array(, dim = c(2,9,num.batch*epoch )) 
for( i in lr_vec){
  res.nn.loss[,which(i==lr_vec),] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb1_loss_",i,".csv")))
}
res.nn.loss <- res.nn.loss[, 1:length(lr_vec),] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
# lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
# lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```


##Comparison of Adam with and without bias
```{r}
num.batch <- 4
epoch <- 20
res.nn.loss <- array(, dim = c(2,2,num.batch*epoch )) 
res.nn.loss[,1,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_adam3_loss_",0.1,".csv")))
res.nn.loss[,2,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adam1_loss_",0.2,".csv")))
```

```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c('method','w/o bias','w bias'), pch = 1,col=c("white",1,3))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)

abline(v=4*1:epoch,lwd=0.2)

legend('topright',legend = c('method','w/o bias','w bias'), pch = 1,col=c("white",1,3))
```


#30 mar
- Look at time taken to load data on Rstudio vs R (ivybridge).... it only takes 1.77 mintues to load on Rstudio

- Visualise the GP of each region (actually probably don't need that) but lets try it anyway, and maybe the ReLU??


*** I am starting t osuspect that my way of inputting data has been wrong, I have been inputting re-arranged data as oppposed to raw data. But I believe that my GP copes with raw data

##Check the result from `viz_gp_test.R`

plotting partial GP (first term of basis)
```{r}
bases.nb <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/roi/partial_gp_",2,"_fixed_",poly_degree,a_concentration,b_smoothness,".feather")))
gp.mask.hs <- mask_subcor
gp.mask.hs[gp.mask.hs!=0] <-bases.nb[1,]
gp.mask.hs@datatype = 16
gp.mask.hs@bitpix = 32
writeNIfTI(gp.mask.hs,paste0('/well/nichols/users/qcv214/bnn2/res3/viz/Reg2_partial_gp'))
```

##Check the test result from `nn_dat_test.R`
This is for re-arranged data
```{r}
num.batch <- 4
epoch <- 10
failed_run <- c(1,3,4)
res.nn.loss.t1 <- array(, dim = c(2,5,num.batch*epoch )) 
for( i in setdiff(1:5,failed_run)){
  res.nn.loss.t1[,i,] <-as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/test_re-arranged_nnb1_loss_0.7_jobid_",i,".csv")))
}
res.nn.loss.t1 <- res.nn.loss.t1[,-failed_run,] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss.t1[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss.t1[1,,])), max(sqrt(res.nn.loss.t1[1,,])))
     ,lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
 lines(sqrt(res.nn.loss.t1[1,2,]),type=line.type,col = 3,lwd=2)
# lines(sqrt(res.nn.loss.t1[1,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss.t1[1,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
# legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss.t1[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss.t1[2,,])), max(sqrt(res.nn.loss.t1[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
 lines(sqrt(res.nn.loss.t1[2,2,]),type=line.type,col = 3,lwd=2)
#  lines(sqrt(res.nn.loss.t1[2,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss.t1[2,7,]),type=line.type,col = 12,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

# legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```


This is for raw data
```{r}
num.batch <- 4
epoch <- 10

failed_run <- c()
res.nn.loss.t2 <- array(, dim = c(2,5,num.batch*epoch )) 
for( i in setdiff(1:5,failed_run)){
  res.nn.loss.t2[,i,] <-as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/test_raw_nnb1_loss_0.7_jobid_",i+5,".csv")))
}
 # res.nn.loss.t2 <- res.nn.loss.t2[,-failed_run,] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss.t2[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss.t2[1,,])), max(sqrt(res.nn.loss.t2[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss.t2[1,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss.t2[1,3,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss.t2[1,4,]),type=line.type,col = 12,lwd=2)
lines(sqrt(res.nn.loss.t2[1,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
# legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss.t2[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss.t2[2,,])), max(sqrt(res.nn.loss.t2[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss.t2[2,2,]),type=line.type,col = 3,lwd=2)
 lines(sqrt(res.nn.loss.t2[2,3,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss.t2[2,4,]),type=line.type,col = 12,lwd=2)
lines(sqrt(res.nn.loss.t2[2,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

# legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```




#31 Mar
After fixing data

##SGD
Load data from `nnb2.R` run 4 is the best
```{r}
learning_rate <- 0.6
num.batch <- 4
epoch <- 40

failed_run <- c(2,3,5,6,7,8,9)
res.nn.loss <- array(, dim = c(2,10,num.batch*epoch )) 
for( i in setdiff(1:10,failed_run)){
  res.nn.loss[,i,] <-as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",learning_rate,"_jobid_",i,".csv")))
}
res.nn.loss <- res.nn.loss[,-failed_run,] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 12,lwd=2)
# lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
# legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
 lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 12,lwd=2)
# lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

# legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```

##Adam
Load data from `nn_adamb2.R` run 4 
```{r}
learning_rate <- 0.1
num.batch <- 4
epoch <- 40

failed_run <- c(2,3,5,6,8)
res.nn.loss <- array(, dim = c(2,10,num.batch*epoch )) 
for( i in setdiff(1:10,failed_run)){
  res.nn.loss[,i,] <-as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adam2_loss_",learning_rate,"_jobid_",i,".csv")))
}
res.nn.loss <- res.nn.loss[,-failed_run,] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 12,lwd=2)
lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
# legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
 lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 10,lwd=2)
lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 12,lwd=2)
lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

# legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```

##AdamW
Load data from `nn_adamWb2.R` run 10
```{r}
learning_rate <- 0.1
num.batch <- 4
epoch <- 40

failed_run <- c(1,2,3,4,5,6,8,9)
res.nn.loss <- array(, dim = c(2,10,num.batch*epoch )) 
for( i in setdiff(1:10,failed_run)){
  res.nn.loss[,i,] <-as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adamW2_loss_",learning_rate,"_jobid_",i,".csv")))
}
res.nn.loss <- res.nn.loss[,-failed_run,] #set range
```
```{r}
line.type <- 'l'
plot(sqrt(res.nn.loss[1,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[1,,])), max(sqrt(res.nn.loss[1,,]))),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[1,2,]),type=line.type,col = 3,lwd=2)
# lines(sqrt(res.nn.loss[1,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[1,4,]),type=line.type,col = 12,lwd=2)
# lines(sqrt(res.nn.loss[1,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)
# legend('bottomleft',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",12))

#out-of-sample
plot(sqrt(res.nn.loss[2,1,]),type=line.type, ylim = c(min(sqrt(res.nn.loss[2,,])), max(sqrt(res.nn.loss[2,,]))),lwd=2,
     main = "Out-of-sample RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(sqrt(res.nn.loss[2,2,]),type=line.type,col = 3,lwd=2)
#  lines(sqrt(res.nn.loss[2,3,]),type=line.type,col = 10,lwd=2)
# lines(sqrt(res.nn.loss[2,4,]),type=line.type,col = 12,lwd=2)
# lines(sqrt(res.nn.loss[2,5,]),type=line.type,col = 14,lwd=2)
abline(v=4*1:epoch,lwd=0.2)

# legend('topright',legend = c('learning_rate',as.character(lr_vec[c(1,2)])), pch = 1,col=c("white",1,2))
```

##Combining all results
```{r}
#SGD
res.nn.loss.sgd <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",4,".csv")))
#Adam
res.nn.loss.adam <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adam2_loss_",0.1,"_jobid_",4,".csv")))
#Adam with decoupled weight decay
res.nn.loss.adamw <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb_adamW2_loss_",0.1,"_jobid_",10,".csv")))
```
###Load whole brain
```{r}
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
wb_23mar<-array(,dim=c(50,3,14))
failed_run<-c()
for(i in setdiff(1:50,failed_run)){
      wb_23mar[i,,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/whole_brain",poly_degree,a_concentration,b_smoothness,"_",i,".csv")))
}
wb_23mar.m<-apply(wb_23mar, c(2,3), median)
```
##Fit horseshoe directly for benchmark
```{r}
hs_31mar<-array(,dim=c(50,13))
failed_run<-c(16,22,39)
for(i in setdiff(1:50,failed_run)){
      hs_31mar[i,] <- t(as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/hs_noscale_",i,".csv"))))
}
hs_31mar <- hs_31mar[-failed_run,]
hs_31mar.m<-apply(hs_31mar, c(2), median)

```
```{r}
min.it <- min(ncol(res.nn.loss.sgd),ncol(res.nn.loss.adam),ncol(res.nn.loss.adamw))
full.res.out <- rbind(sqrt(res.nn.loss.sgd[2,1:min.it]), sqrt(res.nn.loss.adam[2,1:min.it]), sqrt(res.nn.loss.adamw[2,1:min.it]),wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd[1,1:min.it]), sqrt(res.nn.loss.adam[1,1:min.it]), sqrt(res.nn.loss.adamw[1,1:min.it]),wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
SGD took 3.7 hours
Adam took 5 hours
Adam with decoupled weight decay took 9 hours (the other job took 3.5hrs), I think it mainly to do with waiting time
I think the usual time is ~3.5hrs
```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
lines(full.res[1,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('method',"SGD","Adam", "AdamW","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
lines(full.res[2,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c('method',"SGD","Adam", "AdamW","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))
```


To do grid search on prior variance
1.First we can fix all prior variance to be the same then adjust it
2. Second we can vary all prior variance, I think that it should be directly proportional to volume of each region but this is extremely computational intensive and I'd need to re-structure my code as well

To do (1) I will need to
a) find the seed that allow computations to be done on all epochs (is it possible tho since I randomise every epoch... probably not)
b) Vary the prior







#1 April
After meeting with Tom
For variance, we can use the Bayes Empirical Estimator for variance, i.e. use the sample variance (the one generated by our updates). And cross-validate it on another set of data
Also change Cv to 1/2tau^2

Since GP favour thalamus (centre part of brain), try using PCA and see if it detects importance there as well


#2 April

##Grid search
Load my grid search for initial value
```{r}
num.run <- 1:5
prior.var.vec <- c(0.0001,0.0005,0.001,0.01,0.1,0.5,1,5,10)
prior.var.mat <- expand.grid(num.run,prior.var.vec)
```
0.0005, 6
1. 0.001, 11 is interesting (U shape)
2. 0.01, 16 is interesting, 19 is good (U shape)
3. 0.1, 21 is best (validation 22)
4. 0.5, 29 is best (validation 24)
1, 31 (validation 25)

Plot
```{r}
# res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",11,".csv")))
# res.nn.loss.sgd.1[2,30] <-39.8
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",16,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",21,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",29,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]),sqrt(res.nn.loss.sgd.4[2,]),wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]),sqrt(res.nn.loss.sgd.4[1,]),wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
# plot(res.nn.loss.sgd.1[2,])
```

```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
lines(full.res[1,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('pri-var',"0.01", "0.1","0.5","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,5,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
lines(full.res[2,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c('pri-var',"0.01", "0.1","0.5","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,5,2))
```


##Empirical Bayes Estimator
Load theta from SGD with prior var = 0.9
```{r}
theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_theta_",0.6,"_jobid_",4,".feather")))
apply(theta.sgd, 1, sd)
```
Load theta from SGD with prior var = 0.1
```{r}
theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_theta_",0.6,"_jobid_",21,".feather")))
apply(theta.sgd, 1, sd)
```

Compare 0.1 and 0.9
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",21,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb2_loss_",0.6,"_jobid_",4,".csv")))


full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]),wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]),wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```

```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
# lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[1,3,],type=line.type,col = 6,lwd=2)
lines(full.res[1,4,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('pri-var',"0.1", "0.9","GP_reg","Horseshoe"),lty=c(1,2,1,1), pch = c(1,2,20,20),col=c("white",1,3,5,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
# lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[2,3,],type=line.type,col = 6,lwd=2)
lines(full.res[2,4,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c('pri-var',"0.1", "0.9","GP_reg","Horseshoe"),lty=c(1,2,1,1), pch = c(1,2,20,20),col=c("white",1,3,5,2))
```

#10 April

Assess theta variance
num.run <- 1:5
prior.var.vec <- c(0.1,0.5,0.9)
prior.var.mat <- expand.grid(num.run,prior.var.vec)

Compare 0.1, 0.5 and 0.9
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb3_loss_",0.6,"_jobid_",3,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb3_loss_",0.6,"_jobid_",6,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb3_loss_",0.6,"_jobid_",15,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]) ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]) , sqrt(res.nn.loss.sgd.3[1,]) ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
lines(full.res[1,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c('pri-var',"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
lines(full.res[2,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c('pri-var',"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))
```
```{r}
theta.sd.mat <- matrix(,ncol=12,nrow = 3)
counter <- 1
for(i in c(3,6,15)){
  theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb3_theta_",0.6,"_jobid_",i,".feather")))
  theta.sd.mat[counter,] <- apply(theta.sgd, 1, sd)
  counter <- counter+1
}
theta.sd.mat
```
```{r}
plot(theta.sd.mat[1,], ylim = c(0,1), type = "o", lty = 1,pch=1, ylab="s.d.", main = "Region-wise s.d. after 160 iterations", xlab='Region number')
lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
lines(theta.sd.mat[3,], type = "o", lty = 3,pch=3,col = 4)
legend('right',legend = c('prior-var',"0.1","0.5", "0.9"),lty=c(1,1,2,3), pch = c(1,1,2,3),col=c("white",1,3,4))
```


##Load with seed 2
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb4_loss_",0.6,"_seed__jobid_",1,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb4_loss_",0.6,"_seed__jobid_",11,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb4_loss_",0.6,"_seed__jobid_",21,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]) ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]) , sqrt(res.nn.loss.sgd.3[1,]) ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[1,4,],type=line.type,col = 6,lwd=2)
lines(full.res[1,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau),"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[2,4,],type=line.type,col = 6,lwd=2)
lines(full.res[2,5,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau),"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))
```

```{r}
seed <- 2
theta.sd.mat <- matrix(,ncol=12,nrow = 3)
counter <- 1
for(i in c(1,11,21)){
  theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb4_theta_",0.6,"_seed_",seed,"_jobid_",i,".feather")))
  theta.sd.mat[counter,] <- apply(theta.sgd, 1, sd)
  counter <- counter+1
}
theta.sd.mat
```
```{r}
plot(theta.sd.mat[1,], ylim = c(0,1.1), type = "o", lty = 1,pch=1, ylab="s.d.", main = "Region-wise s.d. after 160 iterations", xlab='Region number')
lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
lines(theta.sd.mat[3,], type = "o", lty = 3,pch=3,col = 4)
abline(h=0.1,lty=2,col='grey')
abline(h=0.5,lty=2,col='grey')
abline(h=0.9,lty=2,col='grey')
legend('right',legend = c(expression(tau),"0.1","0.5", "0.9"),lty=c(1,1,2,3), pch = c(1,1,2,3),col=c("white",1,3,4))
```

#7 april

Load result from `privar_tune4.R`
only 13 and 15 (is good) worked
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb5_loss_",0.6,"_seed_",6,"_jobid_",15,".csv")))


full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]) ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]),wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
# lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[1,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[1,2,],type=line.type,col = 6,lwd=2)
lines(full.res[1,3,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau),"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
# lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
# lines(full.res[2,4,], type = "o", lty = 3,pch=3,col = 5,lwd=2)
lines(full.res[2,2,],type=line.type,col = 6,lwd=2)
lines(full.res[2,3,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau),"0.1","0.5", "0.9","GP_reg","Horseshoe"),lty=c(1,1,2,3,1,1), pch = c(1,1,2,3,20,20),col=c("white",1,3,4,6,2))
```


Load grid search
```{r}
  deg_vec<- c(10)
  a_vec  <- c(0.001,0.01,0.1,0.5,1,2,3)
  b_vec  <- 40
  param_grid <- as.matrix(expand.grid(deg_vec,a_vec,b_vec))
  gs.opt <- matrix(,ncol=2,nrow = length(mask.reg))
for(i in sort(mask.reg)){
  gs.opt[which(i==(mask.reg)),]<- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/gs5april_ROI_",i,".csv")))
}
# table(param_grid[gs.opt[,1],1])
table(param_grid[gs.opt[,1],2])
# table(param_grid[gs.opt[,1],3])
```


#11 April
Load data from `privar_tune5.R`
First two sec unusable
25 vs 35
45, 55
65
75, 85 (starting to go up)
##Load with seed 16
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",25,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",35,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",45,".csv"))) #this is the best
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",55,".csv")))
res.nn.loss.sgd.5 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",65,".csv")))
res.nn.loss.sgd.6 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",75,".csv")))
res.nn.loss.sgd.7 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",85,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,]), sqrt(res.nn.loss.sgd.5[2,]), sqrt(res.nn.loss.sgd.6[2,]), sqrt(res.nn.loss.sgd.7[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,]), sqrt(res.nn.loss.sgd.5[1,]), sqrt(res.nn.loss.sgd.6[1,]), sqrt(res.nn.loss.sgd.7[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c(0.0001,0.0005,0.001,0.01,0.1,0.5,1,5,10)
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,], type = "o", lty = 5,pch=5,col = 6,lwd=1)
lines(full.res[1,6,], type = "o", lty = 6,pch=6,col = 7,lwd=1)
lines(full.res[1,7,], type = "o", lty = 7,pch=7,col = 8,lwd=1)
lines(full.res[1,8,],type=line.type,col = 6,lwd=2)
lines(full.res[1,9,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec[-c(1:2)])),lty=c(1,c(1:7)), pch = c(1,c(1:7)),col=c("white",1,3:8))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=2)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,], type = "o", lty = 5,pch=5,col = 6,lwd=1)
lines(full.res[2,6,], type = "o", lty = 6,pch=6,col = 7,lwd=1)
lines(full.res[2,7,], type = "o", lty = 7,pch=7,col = 8,lwd=1)
lines(full.res[2,8,],type=line.type,col = 6,lwd=2)
lines(full.res[2,9,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec[-c(1:2)])),lty=c(1,c(1:7)), pch = c(1,c(1:7)),col=c("white",1,3:8))
```
lr = 0.1 (or 0.5) seems the best 
Look at the theta dist
8 is Basal_Ganglia
```{r}
 theta.sd.mat <- matrix(,ncol=12,nrow = 2)
 counter <- 1
 for(i in c(45,55)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_theta_",0.6,"_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 }
# theta.sd.mat
```
```{r}
 plot(theta.sd.mat[1,], ylim = c(0,1.1), type = "o", lty = 1,pch=1, ylab="var", main = "Region-wise var after 160 iterations", xlab='Region number')
 lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
 abline(h=0.1,lty=2,col='grey')
 abline(h=0.5,lty=2,col='grey')
 legend('topright',legend = c(expression(tau^2),"0.1","0.5"),lty=c(1,1,2), pch = c(1,1,2),col=c("white",1,3))
```
Finally we have something in agreement with variance update


##Load result of gp reg
from `region_gp1`
```{r}
reg_gp<-matrix(,nrow=50,ncol=14)
failed_run<-c()
for(i in setdiff(1:50,failed_run)){
      reg_gp[i,] <- c(as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/pile/region_gp_11apr_",i,".csv"))))
}
reg_gp.m<-apply(reg_gp, c(2), median)
#plot
reg_gp.m[6]
```

Assess theta dist for each region? I'd have to solve a system of lin equations


#Load result of seed 16
```{r}
reg_gp16 <- c(as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/region_gp_11apr_seed16_",1,".csv"))))
reg_gp16[6]
wb_23mar[16,1,6]
```
Look at the theta distribution by solving system of lin equations... can't actually use solve though, solve requires a square matrix.... otherwise not invertible... or need to compute the left inverse 
Moore-penrose generalised inverse `ginv()` from `MASS`
```{r}
library(MASS)
```
Load the fitted horseshoe coef
```{r}
reg_gp16_fitted<- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/region_gp_11apr_coef_seed16_",1,'.feather')))
```

```{r}
norm.func <- function(x){ 2*(x - min(x))/(max(x)-min(x)) -1 }

res3.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
res3.mask.reg <- sort(setdiff(unique(c(res3.mask)),0))
dimension = 3
deg_vec<- c(10)
a_vec  <- c(0.001,0.01,0.1,0.5,1,2,3)
b_vec  <- 40
param_grid <- as.matrix(expand.grid(deg_vec,a_vec,b_vec))
gs.opt <- matrix(,ncol=2,nrow = length(res3.mask.reg))
for(i in sort(res3.mask.reg)){
  gs.opt[which(i==(res3.mask.reg)),]<- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/gs5april_ROI_",i,".csv")))
}
bases.nb.temp <- matrix(,ncol=1,nrow= choose(max(deg_vec)+dimension,dimension)) 

for(i in res3.mask.reg){
  poly_degree = param_grid[gs.opt[which(i==(res3.mask.reg)),1],1] #######I forgot that it must the same poly degree....
  a_concentration= param_grid[gs.opt[which(i==(res3.mask.reg)),1],2]
  b_smoothness= param_grid[gs.opt[which(i==(res3.mask.reg)),1],3]
  mask.temp<-oro.nifti::readNIfTI(paste0('/well/nichols/users/qcv214/bnn2/res3/roi/mask_ROI_',i))
  
  nb <- find_brain_image_neighbors(img1, mask.temp, radius=1)
  #re-scale the coordinates
  nb.centred<- apply(nb$maskcoords,2,norm.func)
  #re-centre each region
  #get psi
  psi.mat.nb <- GP.eigen.funcs.fast(nb.centred, poly_degree = poly_degree, a = a_concentration, b = b_smoothness)
  #get lambda
  lambda.nb <- GP.eigen.value(poly_degree = poly_degree, a = a_concentration, b = b_smoothness, d = dimension)
  #Use Karhunen-Loeve expansion/Mercer's theorem to represent our GP as a combination of gaussian realisation, lambda and psi
  sqrt.lambda.nb <- sqrt(lambda.nb)
  bases.nb <- t(psi.mat.nb)*sqrt.lambda.nb
  if(nrow(bases.nb) < choose(max(deg_vec)+dimension,dimension)){
    empty.expansion <- matrix(0, nrow= choose(max(deg_vec)+dimension,dimension)-nrow(bases.nb), ncol= ncol(bases.nb))
    bases.nb <- rbind(bases.nb,empty.expansion)
  }
  #print(paste0("here, ",i)
  bases.nb.temp <- cbind(as.matrix(bases.nb.temp),as.matrix(bases.nb))
}
colnames(bases.nb.temp) <- NULL
bases.nb <- as.data.frame(bases.nb.temp[,-1])
bases.nb <- as.matrix(bases.nb)
```
Since I fit horseshoe prior as a whole, I shouldn't segment the bases...
This involves finding inverse of the whole matrix
```{r}
overall_theta <- ginv(t(bases.nb))%*%reg_gp16_fitted
qqnorm(overall_theta)
qqline(overall_theta)
```




Load good result so far
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",45,".csv")))
full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]),reg_gp16[6] ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]),reg_gp16[5],wb_23mar.m[1,5],hs_31mar.m[5])
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = line.type, lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[1,3,],type=line.type,col = 6,lwd=2)
lines(full.res[1,4,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c("NN","Region_gp","GP_reg","Horseshoe"),lty=c(1,2,1,1), pch = c(1,20,20,20),col=c(1,3,6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = line.type, lty = 2,pch=2,col = 3,lwd=2)
lines(full.res[2,3,],type=line.type,col = 6,lwd=2)
lines(full.res[2,4,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c("NN","Region_gp","GP_reg","Horseshoe"),lty=c(1,2,1,1), pch = c(1,20,20,20),col=c(1,3,6,2))
```

#14 April

##Load `privar_tune6` for case with inhomogeneous prior variance
And compare it with previous
```{r}
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_loss_",0.6,"_jobid_",5,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_loss_",0.6,"_jobid_",14,".csv"))) #JobId here didn't work, so not the same initialisation
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",45,".csv"))) #this is the best
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",55,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1","0.5","0.1b","0.5b")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
# lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 14,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:4,14,6,2))
#####
plot(full.res[2,2,], type = "o", lty = 2,pch=3, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration", col =3)
# lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
# lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 14,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:4,14,6,2))
```
Plot theta
```{r}
 theta.sd.mat <- matrix(,ncol=12,nrow = 4)
 counter <- 1
 for(i in c(5,14)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_theta_",0.6,"_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 }
 for(i in c(45,55)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_theta_",0.6,"_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 } 
# theta.sd.mat
```
```{r}
 plot(theta.sd.mat[1,], ylim = c(0,1.1), type = "o", lty = 1,pch=1, ylab="var", main = "Region-wise var after 160 iterations", xlab='Region number')
 lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
 lines(theta.sd.mat[3,], type = "o", lty = 3,pch=4,col = 'grey')
 lines(theta.sd.mat[4,], type = "o", lty = 3,pch=4,col = 'grey')
 abline(h=0.1,lty=1,col='grey')
 abline(h=0.5,lty=1,col='grey')
 legend('topright',legend = c(expression(tau^2),"0.1b","0.5b"),lty=c(1,1,2), pch = c(1,1,2),col=c("white",1,3))
```

##Load region-wise NN
Use seed 18 since they are comparable to each other
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_loss_",0.6,"_jobid_",5,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_loss_",0.6,"_jobid_",14,".csv"))) #JobId here didn't work, so not the same initialisation
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_reg1_loss_",0.6,"_jobid_",7,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_reg1_loss_",0.6,"_jobid_",17,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1b","0.5b","0.1 reg-nn","0.5 reg-nn")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))
```

```{r}
 theta.sd.mat <- matrix(,ncol=12,nrow = 4)
 counter <- 1
 for(i in c(7,17)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_reg1_theta_",0.6,"_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 }
# theta.sd.mat
```
```{r}
 plot(theta.sd.mat[1,], ylim = c(0,1.1), type = "o", lty = 1,pch=1, ylab="var", main = "Region-wise var after 160 iterations", xlab='Region number')
 lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
 abline(h=0.1,lty=1,col='grey')
 abline(h=0.5,lty=1,col='grey')
 legend('topright',legend = c(expression(tau^2),"0.1","0.5"),lty=c(1,1,2), pch = c(1,1,2),col=c("white",1,3))
```

Region-wise NN against normal NN
##Load region-wise NN
Use seed 18 since they are comparable to each other
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",45,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb6_loss_",0.6,"_jobid_",55,".csv"))) #JobId here didn't work, so not the same initialisation
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_reg1_loss_",0.6,"_jobid_",7,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nn_reg1_loss_",0.6,"_jobid_",17,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1","0.5","0.1 reg-nn","0.5 reg-nn")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))
```


#21 April
sgd `sgld_sgd1` and `sgld_sgld2`
Learning rate `2*((1e-6)+it.num)^-0.6/2`

```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd1_loss_","_jobid_",1,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd1_loss_","_jobid_",11,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld2_loss_","_jobid_",1,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld2_loss_","_jobid_",11,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1","0.5","0.1 reg-nn","0.5 reg-nn")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))
```
##Load result with amended 
lr = `1*(0.5+it.num)^-0.6/2`
I accidentally fixed prior var to 0.1
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",5,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",15,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld3_loss_","_jobid_",6,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld3_loss_","_jobid_",16,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1","0.5","0.1 reg-nn","0.5 reg-nn")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))
```



##Gridsearch from `gs21april`
Load grid search
```{r}
  deg_vec<- c(10) 
  a_vec  <- c(1,2,3,4,5)
  b_vec  <- c(30,40,50,60,70,80,90,100)
  param_grid <- as.matrix(expand.grid(deg_vec,a_vec,b_vec))
  gs.opt <- matrix(,ncol=2,nrow = length(mask.reg))
for(i in sort(mask.reg)){
  gs.opt[which(i==(mask.reg)),]<- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/gs21april_ROI_",i,".csv")))
}
# table(param_grid[gs.opt[,1],1])
table(param_grid[gs.opt[,1],2])
 table(param_grid[gs.opt[,1],3])
```

#22 April
##Load results fater redoing gridsearch
lr = `1*(0.5+it.num)^-0.6/2`
I accidentally over wrote the result of  `nnsgdlsgd2`
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",4,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",14,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld4_loss_","_jobid_",2,".csv")))
res.nn.loss.sgd.4 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld4_loss_","_jobid_",12,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]), sqrt(res.nn.loss.sgd.4[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]) , sqrt(res.nn.loss.sgd.4[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
prior.var.vec <- c("0.1","0.5","0.1 reg-nn","0.5 reg-nn")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[1,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[1,5,],type=line.type,col = 6,lwd=2)
lines(full.res[1,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))

#out-of-sample
plot(full.res[2,1,], type = "o", lty = 1,pch=1, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=1,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,3,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
lines(full.res[2,4,], type = "o", lty = 4,pch=4,col = 5,lwd=1)
lines(full.res[2,5,],type=line.type,col = 6,lwd=2)
lines(full.res[2,6,],type=line.type,col = 2,lwd=2)
#abline(v=4*1:epoch,lwd=0.2)
legend('topright',legend = c(expression(tau^2),as.character(prior.var.vec)),lty=c(1,c(1:6)), pch = c(1,c(1:6)),col=c("white",1,3:6,2))
```
Load theta for sgd
```{r}
 theta.sd.mat <- matrix(,ncol=12,nrow = 2)
 counter <- 1
 for(i in c(4,14)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_theta_","_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 }

 plot(theta.sd.mat[1,], ylim = c(0,0.7), type = "o", lty = 1,pch=1, ylab="var", main = "Region-wise var after 240 iterations", xlab='Region number')
 lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
 abline(h=0.1,lty=1,col='grey')
 abline(h=0.5,lty=1,col='grey')
 legend('topright',legend = c(expression(tau^2),"0.1","0.5"),lty=c(1,1,2), pch = c(1,1,2),col=c("white",1,3))
```
Load theta for sgld
```{r}
 theta.sd.mat <- matrix(,ncol=12,nrow = 2)
 counter <- 1
 for(i in c(2,12)){
   theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld4_theta_","_jobid_",i,".feather")))
   theta.sd.mat[counter,] <- apply(theta.sgd, 1, var)
   counter <- counter+1
 }

 plot(theta.sd.mat[1,], type = "o", lty = 1,pch=1, ylab="var", main = "Region-wise var after 240 iterations", xlab='Region number')
 lines(theta.sd.mat[2,], type = "o", lty = 2,pch=2,col = 3)
 abline(h=0.1,lty=1,col='grey')
 abline(h=0.5,lty=1,col='grey')
 legend('topright',legend = c(expression(tau^2),"0.1","0.5"),lty=c(1,1,2), pch = c(1,1,2),col=c("white",1,3))
```
Since prior of 0.1 is the best I will focus on this

plot of training vs validation
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",4,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld4_loss_","_jobid_",2,".csv")))

full.res.out <- rbind( sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,])
                       ,wb_23mar.m[1,6],hs_31mar.m[6])
full.res.in <- rbind(sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,])
                     ,wb_23mar.m[1,5],hs_31mar.m[5])

full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
#SGD
prior.var.vec <- c("training","validation")
line.type <- 'l'
plot(full.res[1,1,], type = "o", lty = 1,pch=1,lwd=2,
     main = "RMSE (SGD with prior variance 0.1)",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,1,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('bottomleft',legend = c(as.character(prior.var.vec)),lty=c(1,2), pch = c(1,2),col=c(1,3))

#SGLD
prior.var.vec <- c("training","validation")
line.type <- 'l'
plot(full.res[1,2,], type = "o", lty = 1,pch=1,lwd=2,
     main = "RMSE (SGDL with prior variance 0.1)",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,], type = "o", lty = 2,pch=2,col = 3,lwd=1)

legend('bottomleft',legend = c(as.character(prior.var.vec)),lty=c(1,2), pch = c(1,2),col=c(1,3))
```
Plot of learning rate
```{r}
plot(x=1:240, y =1*(0.5+1:240)^-0.6/2, ylab = "learning rate", xlab = 'iteration',ylim = c(0,0.45))
abline(h=0,lwd=2,col='red')
```

#24 April
lr = `1*(0.5+it.num)^-0.6/2`

##SGD vs 12x12GP SGD
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",2,".csv")))[,1:160]
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd4_loss_","_jobid_",2,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```

Load the result with 12 x 12 gp

```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd4_loss_","_jobid_",10,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld5_loss_","_jobid_",4,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld6_loss_","_jobid_",9,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out

```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,5,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
legend('topright',legend = c("method","SGD","SGLD","SGLD_2","GP Reg","HS-prior"),lty=c(1,c(1:5)), pch = c(1,c(1:5)),col=c("white",1,3:4,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,5,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
#abline(v=4*1:epoch,lwd=0.2)
# legend('topright',legend = c("method","SGD","SGLD","SGLD_2","GP Reg","HS-prior"),lty=c(1,c(1:5)), pch = c(1,c(1:5)),col=c("white",1,3:4,6,2))
```

Can use a more refined mask

#25 April
Consider Cis 4 mask
Note that region `46` and `47` 46,Globus_Pallidus_L 47,Globus_Pallidus_R
`CICatlas_Res4_trunc.txt ` says everything above label 55 is not GM, then threshold at 0.1, so 
```{r}
temp.img <-oro.nifti::readNIfTI('/well/nichols/users/kfh142/data/Atlas/CIC/MultRes/CICatlas_Res4_2mm.nii.gz')
#Take only grey matter
temp.img[temp.img>55] <- 0
temp.img[temp.img==46] <- 0
temp.img[temp.img==47] <- 0
temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,paste0('/well/nichols/users/qcv214/bnn2/res3/maskfix/res4mask_1'))
#Load data with new unthreshold mask
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
part_use<-part_list[part_list$exist_vbm==1,] #4263 participants left
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_use[1:(dim(part_use)[1]),1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
res4.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/maskfix/res4mask_1') 
#threshold at 0.1
dat_colmeans<-colMeans(res4.dat)

#
temp.img[temp.img>0][dat_colmeans<0.1] <- 0 

temp.img@datatype = 2
temp.img@bitpix = 8
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/maskfix/res4mask_3') #Correct
writeNIfTI(temp.img,'/well/nichols/users/qcv214/bnn2/res3/res4mask')

#Load data again using the new thresholded mask
res4.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res4mask') # 4263 x 156812
#save datat
write_feather(as.data.frame(res4.dat), '/well/nichols/users/qcv214/bnn2/res3/res4_dat.feather')
#reload data and mask
res4.dat <- read_feather('/well/nichols/users/qcv214/bnn2/res3/res4_dat.feather') #dim = 4263 156812
res4.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res4mask.nii.gz')
res4.mask.reg <- setdiff(sort(unique(c(res3.mask))),0)
```

#26 April

##Compare SGD with no tuning smoothness and tuning smoothness
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnb7_loss_",0.6,"_jobid_",5,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",5,".csv")))[,1:160]

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD with smoothness tuning","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```


##Compare SGD with fixed lr, 12 GP vs 12x12 GP
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd2_loss_","_jobid_",1,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",8,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD 12x12 GP","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```

##Compare SGD with decaying lr and fixed lr 
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",8,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd4_loss_","_jobid_",8,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD fixed lr","SGD decay lr","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```

##Comparing SGLD with noise variance reduced by 1, 2, 5
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld5_loss_","_jobid_",4,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld6_loss_","_jobid_",9,".csv")))
res.nn.loss.sgd.3 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld7_loss_","_jobid_",4,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]), sqrt(res.nn.loss.sgd.3[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]), sqrt(res.nn.loss.sgd.3[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out

```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[1,5,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
legend('topright',legend = c("method","SGD","SGLD","SGLD_2","GP Reg","HS-prior"),lty=c(1,c(1:5)), pch = c(1,c(1:5)),col=c("white",1,3:4,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
lines(full.res[2,5,], type = "o", lty = 3,pch=3,col = 4,lwd=1)
#abline(v=4*1:epoch,lwd=0.2)
legend('bottomleft',legend = c("method","SGLD","SGLD 1/2","SGLD 1/5","GP Reg","HS-prior"),lty=c(1,c(1:5)), pch = c(1,c(1:5)),col=c("white",1,3:4,6,2))
```
Observe theta at original SGLD
```{r}
theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/short_nnsgdlsgld5_theta_","_jobid_",1,".feather")))
```
```{r}
plot(x=1:12,y=theta.sgd[,8])
```


##Comparing SGLD with noise variance reduced by factor of 5 and fixed lr
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld7_loss_","_jobid_",4,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgld8_loss_","_jobid_",4,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE of SGLD with 1/5 noise variance",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGLD decay","SGLD fixed","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```




##Comparing res3 vs res 4 SGD fixed lr
res4 SGD: `66590926`
none of the jobs manage to finished but also didn't show any error
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",8,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/res4_nnsgdlsgd1_loss_","_jobid_",1,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
Observe sgd5 jobid 8, and Manually load the res 4 sgd job id 8 too

I used `grep -i "training loss" nn.sh.o66590926.8 > ../res4temp.txt`
and `grep -i "validation loss" nn.sh.o66590926.8 > ../res4temp_val.txt`
```{r}
res4.train <- as.matrix(read.delim("/users/nichols/qcv214/res4temp.txt", header = FALSE))
res4.train <- as.numeric(gsub(".*:","",res4.train))
res4.val <- as.matrix(read.delim("/users/nichols/qcv214/res4temp_val.txt", header = FALSE))
res4.val <- as.numeric(gsub(".*:","",res4.val))
```
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",8,".csv")))[,1:192]
res.nn.loss.sgd.2 <- rbind(res4.train,res4.val)[,1:192]

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```


```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(3.5, max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
# lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","12 Regions","55 Regions","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","12 Regions","55 Regions","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```

#27 April

Assess magnitude of theta after 2 epochs/8 ietrations from job `66165476`
```{r}
theta.sgd <- as.matrix(read_feather(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/short_nnsgdlsgld5_theta_","_jobid_",1,".feather")))
```
```{r}
gaus.noise <- matrix(,nrow=12, ncol= 286)
set.seed(12)
for(i in 1:12){
      gaus.noise[i,] <- rnorm(286,0,sqrt((1*(0.5+8)^-0.6/2)*2))
}

```
```{r}
c1 <- rgb(173,216,230,max = 255, alpha = 80, names = "lt.blue")
c2 <- rgb(255,192,203, max = 255, alpha = 80, names = "lt.pink")
for(i in 1:nrow(theta.sgd)){
  hist.temp<-hist(theta.sgd[i,], breaks = seq(from=-10, to=10, by=0.5))
  hist.gaus<-hist(gaus.noise[i,], breaks = seq(from=-10, to=10, by=0.5))
  plot(hist.temp, main = paste0("Region ",i),col=c1, ylim=c(0,120))
  plot(hist.gaus, add = TRUE, col = c2)
}
```

```{r}
for(i in 1:12){
  boxplot(
    abs(gaus.noise[i,]/theta.sgd[i,]), ylab = "Magnitude of relative strength of noise", main = paste0("Boxplot of Region ", i))
}
```

Plot the % changed after adding gaussing noise to theta
```{r}
for(i in 1:12){
  plot((
    gaus.noise[i,])/theta.sgd[i,]*100, ylab=paste0("% change in ", "theta","  with noise"), xlab="basis #", main = paste0("Region ", i))
}
```





#28 Apr 

##Sign wrong for L2 reg
I think I got the sign wrong for penalty, according to https://arxiv.org/pdf/1904.10939 C2 should be negative

Compare if sign had an effect,
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",10,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd7_loss_","_jobid_",10,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD","SGD_2","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD wrong penalty","SGD corrected penalty","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```



#1 May
##Simulation study
Sub-sample res3 by 1/10
```{r}
# res3.dat <- read_feather('/well/nichols/users/qcv214/bnn2/res3/res3_dat.feather') #dim = 4263 124859
res3.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')
res3.mask.reg <- setdiff(sort(unique(c(res3.mask))),0)
```

```{r}
masked.index <- seq_along(res3.mask[res3.mask>0])
res3.mask[res3.mask>0][(masked.index%%10)!=0] <- 0
res3.mask@datatype = 2
res3.mask@bitpix = 8
writeNIfTI(res3.mask,paste0('/well/nichols/users/qcv214/bnn2/res3/sim/res3_sub'))
```
```{r}
sub.res3.mask <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/sim/res3_sub.nii.gz')
sub.res3.mask.reg <- setdiff(sort(unique(c(res3.mask))),0)
```
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
part_use<-part_list[part_list$exist_vbm==1,] #4263 participants left
# 
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_use[1:(dim(part_use)[1]),1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.res3.dat <- fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/sim/res3_sub') # 4263 x 156812
#save datat
write_feather(as.data.frame(sub.res3.dat), '/well/nichols/users/qcv214/bnn2/res3/sim/sub_res3_dat.feather')
```


#2 May
##Plot `sim_hs`
```{r}
hs_2may<-array(,dim=c(20,13))
failed_run<-c(1)
for(i in setdiff(1:20,failed_run)){
      hs_2may[i,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_hs_noscale_",i,".csv")))
}
hs_2may <- hs_2may[-failed_run,]
hs_2may.m<-apply(hs_2may, c(2), median)
hs_2may.m[6]

```


##Plot `sim_hs`
```{r}
poly_degree = 10
a_concentration = 0.5
b_smoothness = 40
wb_2may<-array(,dim=c(20,14))
failed_run<-c(1)
for(i in setdiff(1:20,failed_run)){
      wb_2may[i,] <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_wb_",poly_degree,a_concentration,b_smoothness,"_",i,".csv")))
}
wb_2may <- wb_2may[-failed_run,]
wb_2may.m<-apply(wb_2may, c(2), median)
wb_2may.m[6]
```

```{r}
plot(hs_2may[,6],ylim = c(4.5,5))
lines(wb_2may[,6],col='red')
abline(v=4)
```
From the plot, use `seed 4`

Sanity check if seed 4 of `sim_hs` and `sim_wb` give the same 
```{r}
ind.hs <- read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_hs_index_",4,".csv"))
ind.wb <- read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_wb_index_",4,".csv"))
(sum(ind.hs[1,] == ind.wb[1,])) == 2000 #Yes
```

Load `nnvtrue`
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_nnvtrue_loss__jobid_",1,".csv")))

full.res.out <- rbind( wb_2may[4,6],hs_2may[4,6],
                       sqrt(res.nn.loss.sgd.1[2,]))
full.res.in <- rbind(wb_2may[4,5],hs_2may[4,5],
                     sqrt(res.nn.loss.sgd.1[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
legend('topright',legend = c("method","SGD","GP Reg","HS-prior"),lty=c(1,c(1:3)), pch = c(1,c(1:3)),col=c("white",1,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
legend('topright',legend = c("method","SGD ","GP Reg","HS-prior"),lty=c(1,c(1:3)), pch = c(1,c(1:3)),col=c("white",1,6,2))
```



#3May

##Assess decreasing poly_degree
`sgd4.R` vs `sgd5.R`
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd5_loss_","_jobid_",3,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd6_loss_","_jobid_",13,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(3.5, max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","poly_deg = 10","poly_deg = 6","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","poly_deg = 10","poly_deg = 6","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```


##Assess changing penalty sign
`sgd5.R` vs `sgd6.R`
```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd6_loss_","_jobid_",3,".csv")))
res.nn.loss.sgd.2 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/nnsgdlsgd7_loss_","_jobid_",3,".csv")))

full.res.out <- rbind( wb_23mar.m[1,6],hs_31mar.m[6],
                       sqrt(res.nn.loss.sgd.1[2,]), sqrt(res.nn.loss.sgd.2[2,]))
full.res.in <- rbind(wb_23mar.m[1,5],hs_31mar.m[5],
                     sqrt(res.nn.loss.sgd.1[1,]), sqrt(res.nn.loss.sgd.2[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(3.5, max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[1,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD wrong penalty","SGD corrected penalty","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
lines(full.res[2,4,], type = "o", lty = 2,pch=2,col = 3,lwd=1)
legend('topright',legend = c("method","SGD wrong penalty","SGD corrected penalty","GP Reg","HS-prior"),lty=c(1,c(1:4)), pch = c(1,c(1:4)),col=c("white",1,3,6,2))
```




##For simulation
`gs_v_hs.R` is still not working, I keep getting `warning: chol(): given matrix is not symmetric`
Some are NA because it's my 4000 subjects don't span the entire 4xxx indices in dat.age
<<< Fix, see `gs_v_wb.R`

#5 May
##gs_v_wb
From looking at result of `gs_v_wb` and `gs_v_wb_test`, I have realised that `gs_v_wb` tries to achieve `sim_wb` parameters but cannot as the set of parameter isn't included

##nn_v_wb2
Note that my sim_wb2 and gs uses poly deg = 10, but my nn will use poly_deg = 6

So let wb be the artificial data data, compare nn and hs against it

```{r}
res.nn.loss.sgd.1 <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_nnvwb_loss__jobid_",1,".csv")))

poly_degree = 10
a_concentration = 2 #picked so that it's in the middle of my nn grid search
b_smoothness = 40
wb.res <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_wb2_",poly_degree,a_concentration,b_smoothness,"_",4,".csv")))
hs.res <- as.matrix(read.csv(paste0("/well/nichols/users/qcv214/bnn2/res3/pile/sim_hsvwb_noscale_",1,".csv")))
full.res.out <- rbind( wb.res[6],hs.res[6],
                       sqrt(res.nn.loss.sgd.1[2,]))
full.res.in <- rbind(wb.res[5],hs.res[5],
                     sqrt(res.nn.loss.sgd.1[1,]))
                     
full.res <- array(,dim=c(2,dim(full.res.in)))
full.res[1,,] <- full.res.in
full.res[2,,] <- full.res.out
```
```{r}
line.type <- 'l'
plot(full.res[1,1,],type=line.type,col = 6, ylim = c(min(full.res[1,,]), max(full.res[1,,])),lwd=2,
     main = "Training RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[1,2,],type=line.type,col = 2,lwd=2)
lines(full.res[1,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
legend('topright',legend = c("method","SGD","GP Reg","HS-prior"),lty=c(1,c(1:3)), pch = c(1,c(1:3)),col=c("white",1,6,2))

#out-of-sample
plot(full.res[2,1,],type=line.type,col = 6, ylim = c(min(full.res[2,,]), max(full.res[2,,])),lwd=2,
     main = "Validation RMSE",
     ylab = "Batch RMSE",xlab= "Iteration")
lines(full.res[2,2,],type=line.type,col = 2,lwd=2)
lines(full.res[2,3,], type = "o", lty = 1,pch=1,col = 1,lwd=1)
legend('topright',legend = c("method","SGD ","GP Reg","HS-prior"),lty=c(1,c(1:3)), pch = c(1,c(1:3)),col=c("white",1,6,2))
```


visualise wb2 as real then vs hs coefficients
```{r}
gp.mask.hs <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/bnn2/res3/sim/res3_sub.nii.gz')
gp.mask.hs[gp.mask.hs!=0] <- read_ paste0( '/well/nichols/users/qcv214/bnn2/res3/pile/sim_wb2_coef_',JobId,'.feather'))
gp.mask.hs@datatype = 16
gp.mask.hs@bitpix = 32
writeNIfTI(gp.mask.hs,paste0('/well/nichols/users/qcv214/bnn2/viz/wb_gp_hs_',poly_degree,a_concentration,b_smoothness))
```


